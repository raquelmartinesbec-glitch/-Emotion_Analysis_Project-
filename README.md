# Emotion Analysis Project

Proyecto de an√°lisis de emociones enfocado en generar **datasets sint√©ticos progresivamente m√°s realistas** para evaluaci√≥n de modelos de machine learning.

‚ö†Ô∏è **IMPORTANTE: Todos los datos en este proyecto son completamente artificiales y generados mediante c√≥digo. No contienen informaci√≥n personal real de ninguna persona.**

## üéØ Objetivo del Proyecto

Este proyecto busca **generar usuarios con respuestas emocionales menos espec√≠ficas y crear datos m√°s reales** para probar modelos de machine learning. El desaf√≠o es crear datasets sint√©ticos que presenten la complejidad y ambig√ºedad de datos reales.

### üîÑ Evoluci√≥n de los Datasets

Hemos desarrollado m√∫ltiples generadores de datos sint√©ticos para crear datasets progresivamente m√°s desafiantes:

1. **Datos aleatorios** ‚Üí 20% accuracy (nivel azar)
2. **Datos coherentes** ‚Üí 95%+ accuracy (demasiado f√°cil, overfitting)
3. **Datos realistas** ‚Üí 65-80% accuracy (objetivo actual)

## Estructura del Proyecto

```
Emotion_Analysis_Project/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ data_emotions_coherent.csv           # Dataset coherente (f√°cil)
‚îÇ   ‚îú‚îÄ‚îÄ data_clean_emotions_coherent.csv     # Procesado coherente
‚îÇ   ‚îú‚îÄ‚îÄ data_emotions_realistic_medium.csv   # Dataset realista (desafiante)
‚îÇ   ‚îî‚îÄ‚îÄ data_clean_emotions_realistic.csv    # Procesado realista
‚îú‚îÄ‚îÄ generate_coherent_dataset.py             # Genera datos con patrones claros
‚îú‚îÄ‚îÄ generate_realistic_dataset.py            # Genera datos con ambig√ºedad real
‚îú‚îÄ‚îÄ clean_emotions_data.py                   # Procesa cualquier dataset
‚îú‚îÄ‚îÄ model_training.py                        # Entrenamiento con detecci√≥n de overfitting
‚îú‚îÄ‚îÄ Inconsistencia_en_los_datosC.ipynb       # An√°lisis de inconsistencias - Dataset Coherente
‚îú‚îÄ‚îÄ Incosistencia_en_los_datosR.ipynb        # An√°lisis de inconsistencias - Dataset Realista
‚îî‚îÄ‚îÄ README.md                               # Este archivo
```

## üìä Datasets Actuales

### üéØ Dataset Realista (Recomendado)
**Archivo:** `data_emotions_realistic_medium.csv` ‚Üí `data_clean_emotions_realistic.csv`

- **Registros:** 1,200
- **Textos √∫nicos:** ~80% (simulando duplicados naturales)
- **Vocabulario:** 60% espec√≠fico + 40% ambiguo entre emociones
- **Ruido:** 5% de etiquetas incorrectas (simulando errores humanos)
- **Accuracy esperado:** 65-80% (realista)

**Caracter√≠sticas clave:**
- Palabras ambiguas compartidas entre emociones ("malo" puede ser tristeza o enojo)
- Patrones complejos que requieren aprendizaje real
- Vocabulario superpuesto entre categor√≠as emocionales
- Desaf√≠o similar a datos del mundo real

### üìö Dataset Coherente (Referencia)
**Archivo:** `data_emotions_coherent.csv` ‚Üí `data_clean_emotions_coherent.csv`

- **Registros:** 1,000
- **Vocabulario espec√≠fico:** 100% por emoci√≥n
- **Patrones claros:** Palabras √∫nicas para cada emoci√≥n
- **Accuracy esperado:** 95%+ (demasiado f√°cil)

**Uso:** Validar que el pipeline funciona correctamente antes de probar con datos realistas.

## üß™ Justificaci√≥n del Enfoque

### ‚ùå Problema Identificado
Los datasets sint√©ticos tradicionales producen **accuracy artificialmente alto (100%)** porque:
- Vocabulario demasiado espec√≠fico por emoci√≥n
- Sin ambig√ºedad entre categor√≠as
- Patrones demasiado obvios para los algoritmos

### ‚úÖ Soluci√≥n Implementada
**Datasets realistas** que incluyen:
- **Vocabulario ambiguo:** Palabras que pueden expresar m√∫ltiples emociones
- **Solapamiento sem√°ntico:** "terrible" puede ser tristeza, enojo o miedo
- **Ruido realista:** 5% de etiquetas incorrectas
- **Duplicados naturales:** Como ocurre en datos reales

### üéØ Resultado Esperado
- **Accuracy realista:** 65-80% (similar a datasets reales)
- **Aprendizaje genuino:** El modelo debe encontrar patrones complejos
- **Evaluaci√≥n confiable:** M√©tricas que reflejen rendimiento real
## üõ†Ô∏è Scripts Disponibles

### 1. Generar Dataset Coherente (F√°cil)
```python
python generate_coherent_dataset.py
```
**Uso:** Validar que el pipeline funciona. Produce 95%+ accuracy.

### 2. Generar Dataset Realista (Desafiante)
```python
python generate_realistic_dataset.py
```
**Uso:** Crear datos con ambig√ºedad real. Objetivo de 65-80% accuracy.

### 3. Procesar y Limpiar Datos
```python
python clean_emotions_data.py
```
**Autom√°ticamente detecta y procesa el √∫ltimo dataset generado.**

### 4. Entrenar y Evaluar Modelos
```python
python model_training.py
```
**Incluye detecci√≥n de overfitting y an√°lisis de rendimiento.**

### 5. An√°lisis de Inconsistencias - Notebooks Interactivos

#### üìä Inconsistencia_en_los_datosC.ipynb
**An√°lisis exhaustivo del dataset coherente:**
- Comparaci√≥n entre datos originales y procesados
- Vectorizaci√≥n TF-IDF y entrenamiento Random Forest
- An√°lisis SHAP para interpretabilidad
- Cross-validation con m√©tricas detalladas por emoci√≥n

#### üìä Incosistencia_en_los_datosR.ipynb  
**An√°lisis exhaustivo del dataset realista:**
- Evaluaci√≥n de ambig√ºedad en vocabulario emocional
- Detecci√≥n de inconsistencias en datos m√°s complejos
- An√°lisis de rendimiento en condiciones realistas
- M√©tricas comparativas con el dataset coherente

**Caracter√≠sticas de ambos notebooks:**
- üîç An√°lisis SHAP para explicabilidad de modelos
- üìà Cross-validation estratificado (5-folds)
- üìä Reports detallados por clase emocional
- üéØ Visualizaciones de dependencia de caracter√≠sticas
- üß™ Comparaci√≥n de accuracy entre datasets originales y procesados

## üìà Estructura de Datos

**Todas las versiones comparten la misma estructura:**
- `user_id`: ID √∫nico del usuario (UUID)
- `timestamp`: Fecha y hora del registro
- `text`: Texto emocional del usuario
- `emotion`: Categor√≠a emocional (feliz, triste, enojado, sorprendido, neutral)
- `age`: Edad del usuario (18-70 a√±os)
- `gender`: G√©nero (masculino, femenino, no binario)
- `region`: Regi√≥n geogr√°fica (Norte, Sur, Este, Oeste, Centro)

**Despu√©s del procesamiento:**
- Variables categ√≥ricas codificadas con One-Hot
- Texto limpio (min√∫sculas, sin puntuaci√≥n)
- TF-IDF vectorization (calculado en tiempo real)

## üß† Metodolog√≠a de Machine Learning

### Medidas Anti-Overfitting
- **Eliminaci√≥n de duplicados:** Detecta y remueve textos id√©nticos
- **Divisi√≥n estratificada:** 70% entrenamiento, 30% prueba
- **Cross-validation:** 5-fold StratifiedKFold
- **Regularizaci√≥n:** LogisticRegression con C=0.1
- **Detecci√≥n de data leakage:** Excluye caracter√≠sticas pre-procesadas

### Modelos Evaluados
1. **Solo texto (TF-IDF):** Base para an√°lisis de sentimientos
2. **Solo demograf√≠a:** Control de variables no textuales
3. **Texto + demograf√≠a:** Modelo combinado
4. **Random Forest:** Algoritmo alternativo

### M√©tricas de Evaluaci√≥n
- **Accuracy:** Con contexto de baseline aleatorio (20%)
- **Cross-validation:** Para validar generalizaci√≥n
- **Matriz de confusi√≥n:** Errores por categor√≠a
- **Precision/Recall/F1:** Rendimiento por emoci√≥n

## üéØ Benchmark de Rendimiento

| Tipo de Dataset | Accuracy Esperado | Interpretaci√≥n |
|------------------|-------------------|----------------|
| Aleatorio | ~20% | Nivel de azar (5 clases) |
| Coherente | 95%+ | ‚ö†Ô∏è Demasiado f√°cil, posible overfitting |
| **Realista** | **65-80%** | ‚úÖ **Objetivo: Realista y desafiante** |

## üî¨ Investigaci√≥n y Desarrollo

### üìä An√°lisis de Inconsistencias de Datos

Hemos implementado un an√°lisis exhaustivo para detectar y evaluar inconsistencias en ambos datasets utilizando t√©cnicas avanzadas de machine learning y SHAP (SHapley Additive exPlanations).

#### üß™ Notebooks de An√°lisis

1. **Inconsistencia_en_los_datosC.ipynb** - An√°lisis del Dataset Coherente
   - Comparaci√≥n entre datos originales (`data_emotions_coherent.csv`) y procesados (`data_clean_emotions_coherent.csv`)
   - Vectorizaci√≥n TF-IDF con 500 caracter√≠sticas m√°s frecuentes
   - Entrenamiento de Random Forest (n_estimators=100)
   - An√°lisis SHAP para interpretabilidad del modelo
   - Cross-validation con StratifiedKFold (n_splits=5)
   - M√©tricas detalladas por clase emocional

2. **Incosistencia_en_los_datosR.ipynb** - An√°lisis del Dataset Realista
   - Comparaci√≥n entre datos originales (`data_emotions_realistic_medium.csv`) y procesados (`data_clean_emotions_realistic.csv`)
   - Misma metodolog√≠a aplicada al dataset m√°s desafiante
   - An√°lisis de rendimiento en condiciones realistas
   - Evaluaci√≥n de la ambig√ºedad del vocabulario

#### üîç Metodolog√≠a de An√°lisis

**T√©cnicas Implementadas:**
- **TF-IDF Vectorization:** Hasta 5000 caracter√≠sticas para an√°lisis detallado
- **Random Forest:** Modelo ensemble para capturar patrones complejos
- **SHAP Analysis:** Explicabilidad de predicciones mediante valores Shapley
- **Cross-Validation:** Validaci√≥n robusta con 5 folds estratificados
- **Classification Reports:** M√©tricas detalladas por clase emocional

**M√©tricas Evaluadas:**
- Accuracy por fold y promedio general
- Precision, Recall y F1-score por emoci√≥n
- Matriz de confusi√≥n para an√°lisis de errores
- SHAP values para interpretaci√≥n de caracter√≠sticas importantes
- Dependence plots para an√°lisis de palabras espec√≠ficas

#### üìà Hallazgos Principales

**Dataset Coherente:**
- **Alta consistencia:** Palabras espec√≠ficas claramente asociadas a emociones
- **Patrones evidentes:** F√°cil separabilidad entre clases
- **Interpretabilidad clara:** SHAP values muestran caracter√≠sticas distintivas
- **Overfitting potencial:** Accuracy muy alto sugiere simplicidad excesiva

**Dataset Realista:**
- **Ambig√ºedad natural:** Palabras compartidas entre emociones m√∫ltiples
- **Desaf√≠o real:** Menor accuracy refleja complejidad del mundo real
- **Patrones sutiles:** SHAP revela relaciones m√°s complejas
- **Generalizaci√≥n mejorada:** Mejor preparaci√≥n para datos reales

#### üõ†Ô∏è Herramientas de An√°lisis

Las t√©cnicas implementadas permiten:
- **Detecci√≥n de inconsistencias** en etiquetado de emociones
- **Identificaci√≥n de patrones** de vocabulario emocional
- **Evaluaci√≥n de calidad** de datasets sint√©ticos
- **Optimizaci√≥n de modelos** mediante interpretabilidad
- **Validaci√≥n cruzada robusta** para m√©tricas confiables

### Pr√≥ximos Pasos
1. **Aumentar ambig√ºedad:** M√°s solapamiento de vocabulario
2. **Contexto complejo:** Frases con emociones mixtas
3. **Ruido realista:** Simulaci√≥n de errores de etiquetado humano
4. **Datos multimodales:** Incorporar metadata temporal/demogr√°fica

### Casos de Uso
- **Investigaci√≥n:** Evaluaci√≥n realista de modelos de NLP
- **Educaci√≥n:** Ense√±anza de machine learning con datos challenging
- **Desarrollo:** Testing de algoritmos de an√°lisis de sentimientos
- **Benchmarking:** Comparaci√≥n de t√©cnicas de procesamiento de texto

## Requisitos

```bash
# Dependencias b√°sicas del proyecto
pip install pandas numpy faker scikit-learn scipy

# Dependencias adicionales para an√°lisis de inconsistencias
pip install matplotlib seaborn shap jupyter

# Instalaci√≥n completa recomendada
pip install pandas numpy faker scikit-learn scipy matplotlib seaborn shap jupyter
```

**Dependencias por funcionalidad:**
- **Generaci√≥n de datos:** `pandas`, `numpy`, `faker`
- **Machine learning:** `scikit-learn`, `scipy`
- **An√°lisis de inconsistencias:** `matplotlib`, `seaborn`, `shap`
- **Notebooks interactivos:** `jupyter`

## üìÑ Licencia

**DATOS SINT√âTICOS - USO LIBRE**

Este proyecto utiliza datos completamente artificiales. Libre para uso educativo, investigaci√≥n y comercial sin restricciones.

---

## üéØ **Conclusiones: Impacto de las Inconsistencias en la Efectividad del Modelo**

### üìä **An√°lisis Comparativo de Coherencia de Datos**

Nuestro an√°lisis exhaustivo mediante los notebooks de inconsistencias revela patrones cr√≠ticos que afectan directamente la efectividad de los modelos de machine learning:

#### üî¥ **Factores que Reducen la Efectividad del Modelo**

**1. Ambig√ºedad Sem√°ntica**
- **Vocabulario superpuesto:** Palabras como "malo", "terrible" aparecen en m√∫ltiples emociones (tristeza, enojo, miedo)
- **Impacto:** El modelo no puede establecer relaciones claras entre caracter√≠sticas y etiquetas
- **Evidencia SHAP:** Los valores de importancia se distribuyen inconsistentemente entre palabras ambiguas

**2. Ruido en Etiquetado**
- **5% de etiquetas incorrectas** en el dataset realista simula errores humanos reales
- **Impacto:** Confunde el algoritmo durante el entrenamiento, reduciendo la confianza en predicciones
- **Resultado:** Accuracy baja de 95% (coherente) a 65-80% (realista)

**3. Inconsistencia en Patrones Textuales**
- **Dataset coherente:** Cada emoci√≥n tiene vocabulario √∫nico y espec√≠fico
- **Dataset realista:** M√∫ltiples emociones comparten el mismo vocabulario base
- **Consecuencia:** El modelo debe aprender relaciones m√°s sutiles y contextuales

#### ‚úÖ **Validaci√≥n de Hip√≥tesis**

**Comparaci√≥n de Rendimiento:**
| Aspecto | Dataset Coherente | Dataset Realista | Impacto en Efectividad |
|---------|-------------------|------------------|------------------------|
| **Accuracy** | 95%+ | 65-80% | ‚¨áÔ∏è **-15 a -30%** |
| **Separabilidad** | Clara | Ambigua | ‚¨áÔ∏è **Decisiones inciertas** |
| **Interpretabilidad SHAP** | Espec√≠fica | Distribuida | ‚¨áÔ∏è **Explicaciones confusas** |
| **Generalizaci√≥n** | Overfitting | Robusta | ‚úÖ **Mejor en datos reales** |

#### üß† **Mecanismos de Impacto Identificados**

**1. Degradaci√≥n de la Funci√≥n de P√©rdida**
- Las inconsistencias crean **contradicciones** en los datos de entrenamiento
- El modelo no puede minimizar eficientemente la p√©rdida
- **Resultado:** Convergencia lenta y rendimiento sub√≥ptimo

**2. Reducci√≥n de la Capacidad Predictiva**
- **Caracter√≠sticas ruidosas** dominan sobre se√±ales genuinas
- El modelo aprende patrones espurios en lugar de relaciones reales
- **Consecuencia:** Predicciones menos confiables

**3. Complejidad de Decisi√≥n Aumentada**
- **Fronteras de decisi√≥n difusas** entre clases emocionales
- Requiere algoritmos m√°s sofisticados para capturar sutilezas
- **Trade-off:** Mayor realismo vs menor accuracy inmediata

#### üéØ **Implicaciones para el Mundo Real**

**Lecciones Aprendidas:**

1. **La coherencia perfecta es irreal:** Los datos del mundo real siempre contienen ambig√ºedades
2. **El overfitting es peligroso:** Un accuracy del 95% en datos sint√©ticos puede ser enga√±oso
3. **La ambig√ºedad es valiosa:** Datasets realistas preparan mejor los modelos para casos reales
4. **La interpretabilidad sufre:** SHAP muestra patrones m√°s complejos en datos inconsistentes

**Recomendaciones Estrat√©gicas:**

- ‚úÖ **Usar datasets realistas** para evaluaci√≥n final de modelos
- ‚úÖ **Validar con cross-validation** para detectar overfitting
- ‚úÖ **Analizar SHAP values** para entender decisiones del modelo
- ‚úÖ **Aceptar accuracy menor** si refleja condiciones reales
- ‚ö†Ô∏è **Desconfiar de accuracy > 90%** en datos emocionales complejos

#### üìà **Valor del An√°lisis de Inconsistencias**

Este proyecto demuestra que **la inconsistencia controlada en datos sint√©ticos** es fundamental para:
- **Evaluaci√≥n realista** de algoritmos de NLP
- **Preparaci√≥n robusta** de modelos para producci√≥n
- **Comprensi√≥n profunda** de limitaciones algor√≠tmicas
- **Desarrollo responsable** de IA emocional

**Conclusi√≥n Final:** Las inconsistencias en los datos, aunque reducen m√©tricas superficiales como el accuracy, **mejoran significativamente** la capacidad del modelo para generalizar a datos reales, proporcionando una evaluaci√≥n m√°s honesta y √∫til del rendimiento algor√≠tmico.