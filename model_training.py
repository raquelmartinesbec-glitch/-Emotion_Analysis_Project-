import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import cross_val_score, train_test_split
from scipy.sparse import hstack

# Cargar el dataset limpio
print("Cargando dataset limpio...")

# Verificar archivos disponibles
import os
print("Archivos en el directorio actual:")
print(os.listdir('.'))

# Verificar si existe la carpeta data
if os.path.exists('data'):
    print("\nArchivos en la carpeta data:")
    print(os.listdir('data'))
    # USAR el dataset realista (datos con correlaciÃ³n texto-emociÃ³n MÃS DESAFIANTE)
    data_path = 'data/data_clean_emotions_realistic.csv'
    if not os.path.exists(data_path):
        print("âš ï¸ Dataset realista no encontrado. GenerÃ¡ndolo...")
        print("Ejecuta: python generate_realistic_dataset.py")
        print("Luego: python clean_emotions_data.py")
        exit()
else:
    # Buscar el archivo en el directorio actual
    csv_files = [f for f in os.listdir('.') if f.endswith('.csv')]
    print(f"\nArchivos CSV disponibles: {csv_files}")
    
    # Intentar con diferentes nombres posibles
    possible_files = [
        'data_clean_emotions_realistic.csv',  # Dataset realista (prioridad)
        'data_clean_emotions_coherent.csv',   # Dataset coherente (backup)
        'data_clean_emotions_1000.csv',
        'data_clean_emotions.csv',
        'data_emociones_faker.csv'
    ]
    
    data_path = None
    for file in possible_files:
        if file in csv_files:
            data_path = file
            break
    
    if data_path is None and csv_files:
        data_path = csv_files[0]  # Usar el primer CSV encontrado
        print(f"Usando archivo: {data_path}")

if data_path and os.path.exists(data_path):
    data_clean = pd.read_csv(data_path)
    print(f"Dataset cargado desde {data_path} con forma: {data_clean.shape}")
else:
    print("ERROR: No se encontrÃ³ el dataset coherente.")
    print("Ejecuta estos comandos para generar datos coherentes:")
    print("1. python generate_coherent_dataset.py")
    print("2. python clean_emotions_data.py")
    exit()

# Mostrar primeras filas y info del dataset
print("\nPrimeras 5 filas:")
print(data_clean.head())

print(f"\nColumnas disponibles: {list(data_clean.columns)}")

# Preparar los datos
# Separar texto original y caracterÃ­sticas procesadas
text_column = 'text_clean'  # Usar el texto limpio
target_column = 'emotion'

# Obtener el texto limpio y el target
X_text = data_clean[text_column]
y = data_clean[target_column]

# Obtener caracterÃ­sticas demogrÃ¡ficas (excluyendo texto, TF-IDF pre-procesado, id, timestamp y emotion)
exclude_cols = ['user_id', 'timestamp', 'text', 'text_clean', 'emotion'] + [col for col in data_clean.columns if col.startswith('tfidf_')]
demographic_cols = [col for col in data_clean.columns if col not in exclude_cols]
X_demographic = data_clean[demographic_cols]

print(f"\nâš ï¸ EVITANDO DATA LEAKAGE: Excluyendo {len([col for col in data_clean.columns if col.startswith('tfidf_')])} caracterÃ­sticas TF-IDF pre-procesadas")
print(f"CaracterÃ­sticas demogrÃ¡ficas utilizadas: {len(demographic_cols)}")
print(f"Columnas demogrÃ¡ficas: {demographic_cols}")

# DivisiÃ³n train/test con mÃ¡s validaciÃ³n
print("\nğŸ” ANÃLISIS DE DUPLICADOS Y DISTRIBUCIÃ“N:")
print(f"Textos Ãºnicos: {X_text.nunique()} de {len(X_text)} ({X_text.nunique()/len(X_text)*100:.1f}%)")

# Verificar si hay texto duplicado
duplicates = X_text.duplicated().sum()
if duplicates > 0:
    print(f"âš ï¸ ADVERTENCIA: {duplicates} textos duplicados detectados")
    print("ğŸ’¡ Esto puede causar overfitting artificial")
    
    # ELIMINAR DUPLICADOS para evitar data leakage
    print("ğŸ§¹ ELIMINANDO DUPLICADOS...")
    original_size = len(data_clean)
    data_clean_unique = data_clean.drop_duplicates(subset=['text_clean'], keep='first')
    removed = original_size - len(data_clean_unique)
    
    print(f"   Registros originales: {original_size}")
    print(f"   Registros Ãºnicos: {len(data_clean_unique)}")
    print(f"   Duplicados eliminados: {removed}")
    
    # Actualizar variables con datos Ãºnicos
    X_text = data_clean_unique[text_column]
    y = data_clean_unique[target_column]
    X_demographic = data_clean_unique[demographic_cols]
    
    print(f"âœ… Dataset sin duplicados: {len(data_clean_unique)} registros")

X_text_train, X_text_test, y_train, y_test = train_test_split(
    X_text, y, test_size=0.3, random_state=42, stratify=y  # Aumentar test set
)

X_demo_train, X_demo_test = train_test_split(
    X_demographic, test_size=0.3, random_state=42, stratify=y  # Coincidir con text split
)

print(f"\nDatos de entrenamiento: {len(X_text_train)}")
print(f"Datos de prueba: {len(X_text_test)}")

# Crear vectorizador TF-IDF (CALCULAR DESDE CERO para evitar data leakage)
print("\nğŸš¨ IMPORTANTE: Calculando TF-IDF desde texto crudo para evitar data leakage")
tfidf = TfidfVectorizer(
    max_features=1000,  # Reducir caracterÃ­sticas para hacer mÃ¡s difÃ­cil
    stop_words='english',
    ngram_range=(1, 2),  # Incluir bigramas para mÃ¡s variedad
    min_df=2,  # Palabra debe aparecer al menos 2 veces
    max_df=0.8  # Excluir palabras muy frecuentes
)

# Entrenar TF-IDF sobre los textos del train
print("\nEntrenando vectorizador TF-IDF...")
X_text_train_tfidf = tfidf.fit_transform(X_text_train)
X_text_test_tfidf = tfidf.transform(X_text_test)

print(f"CaracterÃ­sticas TF-IDF: {X_text_train_tfidf.shape[1]}")

# OpciÃ³n 1: Solo texto (TF-IDF) con regularizaciÃ³n
print("\n=== MODELO SOLO CON TEXTO (CON REGULARIZACIÃ“N) ===")
lr_text = LogisticRegression(
    random_state=42, 
    max_iter=1000,
    C=0.1,  # Aumentar regularizaciÃ³n
    solver='lbfgs'  # Mejor para multiclass
)
lr_text.fit(X_text_train_tfidf, y_train)

# Predicciones
y_pred_text = lr_text.predict(X_text_test_tfidf)

# Accuracy
accuracy_text = accuracy_score(y_test, y_pred_text)
print(f"Accuracy solo texto: {accuracy_text:.4f}")

# Cross-validation
from sklearn.model_selection import StratifiedKFold
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores_text = cross_val_score(lr_text, X_text_train_tfidf, y_train, cv=skf, scoring='accuracy')
print(f"CV Accuracy: {cv_scores_text.mean():.4f} (+/- {cv_scores_text.std() * 2:.4f})")
print(f"CV scores individuales: {[f'{score:.3f}' for score in cv_scores_text]}")

# Reporte detallado
print("\nReporte de clasificaciÃ³n (solo texto):")
print(classification_report(y_test, y_pred_text))

# OpciÃ³n 2: Solo caracterÃ­sticas demogrÃ¡ficas
print("\n=== MODELO SOLO DEMOGRAFÃA ===")
lr_demo = LogisticRegression(random_state=42, max_iter=1000)
lr_demo.fit(X_demo_train, y_train)

# Predicciones
y_pred_demo = lr_demo.predict(X_demo_test)

# Accuracy
accuracy_demo = accuracy_score(y_test, y_pred_demo)
print(f"Accuracy solo demografÃ­a: {accuracy_demo:.4f}")

# Cross-validation
cv_scores_demo = cross_val_score(lr_demo, X_demo_train, y_train, cv=skf, scoring='accuracy')
print(f"CV Accuracy: {cv_scores_demo.mean():.4f} (+/- {cv_scores_demo.std() * 2:.4f})")
print(f"CV scores individuales: {[f'{score:.3f}' for score in cv_scores_demo]}")

# Reporte detallado
print("\nReporte de clasificaciÃ³n (solo demografÃ­a):")
print(classification_report(y_test, y_pred_demo))

# OpciÃ³n 3: Combinar texto + caracterÃ­sticas demogrÃ¡ficas
print("\n=== MODELO TEXTO + DEMOGRAFÃA ===")

# Combinar TF-IDF con caracterÃ­sticas demogrÃ¡ficas
X_combined_train = hstack([X_text_train_tfidf, X_demo_train.values])
X_combined_test = hstack([X_text_test_tfidf, X_demo_test.values])

# Entrenar modelo combinado
lr_combined = LogisticRegression(random_state=42, max_iter=1000)
lr_combined.fit(X_combined_train, y_train)

# Predicciones
y_pred_combined = lr_combined.predict(X_combined_test)

# Accuracy
accuracy_combined = accuracy_score(y_test, y_pred_combined)
print(f"Accuracy texto + demografÃ­a: {accuracy_combined:.4f}")

# Cross-validation
cv_scores_combined = cross_val_score(lr_combined, X_combined_train, y_train, cv=skf, scoring='accuracy')
print(f"CV Accuracy: {cv_scores_combined.mean():.4f} (+/- {cv_scores_combined.std() * 2:.4f})")
print(f"CV scores individuales: {[f'{score:.3f}' for score in cv_scores_combined]}")

# Reporte detallado
print("\nReporte de clasificaciÃ³n (texto + demografÃ­a):")
print(classification_report(y_test, y_pred_combined))

# OpciÃ³n 4: Random Forest con texto + demografÃ­a
print("\n=== RANDOM FOREST TEXTO + DEMOGRAFÃA ===")
rf_combined = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
rf_combined.fit(X_combined_train, y_train)

# Predicciones
y_pred_rf = rf_combined.predict(X_combined_test)

# Accuracy
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print(f"Random Forest Accuracy: {accuracy_rf:.4f}")

# Cross-validation
cv_scores_rf = cross_val_score(rf_combined, X_combined_train, y_train, cv=skf, scoring='accuracy')
print(f"CV Accuracy: {cv_scores_rf.mean():.4f} (+/- {cv_scores_rf.std() * 2:.4f})")
print(f"CV scores individuales: {[f'{score:.3f}' for score in cv_scores_rf]}")

# Reporte detallado
print("\nReporte de clasificaciÃ³n (Random Forest):")
print(classification_report(y_test, y_pred_rf))

# Resumen comparativo
print("\n=== RESUMEN COMPARATIVO ===")
print(f"Solo Texto:           {accuracy_text:.4f}")
print(f"Solo DemografÃ­a:      {accuracy_demo:.4f}")
print(f"Texto + DemografÃ­a:   {accuracy_combined:.4f}")
print(f"Random Forest:        {accuracy_rf:.4f}")

# Matriz de confusiÃ³n para el mejor modelo
print(f"\n=== MATRIZ DE CONFUSIÃ“N (MEJOR MODELO) ===")
best_accuracy = max(accuracy_text, accuracy_demo, accuracy_combined, accuracy_rf)
if best_accuracy == accuracy_text:
    best_model_name = "Solo Texto"
    best_predictions = y_pred_text
elif best_accuracy == accuracy_demo:
    best_model_name = "Solo DemografÃ­a"
    best_predictions = y_pred_demo
elif best_accuracy == accuracy_combined:
    best_model_name = "Texto + DemografÃ­a"
    best_predictions = y_pred_combined
else:
    best_model_name = "Random Forest"
    best_predictions = y_pred_rf

print(f"Mejor modelo: {best_model_name} (Accuracy: {best_accuracy:.4f})")
print("\nMatriz de confusiÃ³n:")
cm = confusion_matrix(y_test, best_predictions)
print(cm)

# Mostrar etiquetas de emociones
emotions = sorted(y.unique())
print(f"\nEtiquetas de emociones: {emotions}")

# AnÃ¡lisis adicional del rendimiento
print(f"\n=== ANÃLISIS DEL RENDIMIENTO ===")

# Baseline (precisiÃ³n aleatoria)
from collections import Counter
emotion_counts = Counter(y)
total_samples = len(y)
baseline_accuracy = max(emotion_counts.values()) / total_samples
random_accuracy = 1 / len(emotions)

print(f"Accuracy aleatorio esperado: {random_accuracy:.4f} ({random_accuracy*100:.1f}%)")
print(f"Baseline (clase mayoritaria): {baseline_accuracy:.4f} ({baseline_accuracy*100:.1f}%)")
print(f"Mejor modelo obtenido: {best_accuracy:.4f} ({best_accuracy*100:.1f}%)")

# Verificar si el modelo estÃ¡ aprendiendo algo
if best_accuracy > random_accuracy * 1.2:  # 20% mejor que aleatorio
    print("âœ… El modelo estÃ¡ aprendiendo algo (mejor que aleatorio)")
else:
    print("âŒ El modelo no estÃ¡ aprendiendo (similar a aleatorio)")

# AnÃ¡lisis segÃºn el tipo de dataset
if 'realistic' in data_path:
    print(f"\n=== USANDO DATASET REALISTA (RECOMENDADO) ===")
    print("âœ… DATOS DESAFIANTES: Texto con ambigÃ¼edad y solapamiento de vocabulario")
    print("âœ… VOCABULARIO MIXTO: 60% especÃ­fico + 40% ambiguo entre emociones")
    print("âœ… ETIQUETAS RUIDOSAS: 5% de ruido para simular errores humanos")
    print("âœ… PATRONES COMPLEJOS: Requiere aprendizaje real de patrones semÃ¡nticos")
    print("ğŸ¯ OBJETIVO: Simular la complejidad de datos del mundo real")
    if best_accuracy > 0.85:
        print("ğŸ‰ EXCELENTE: Accuracy muy alto con dataset desafiante")
        print("ğŸ’¡ Este resultado sugiere un modelo robusto que puede manejar ambigÃ¼edad")
    elif best_accuracy > 0.7:
        print("âœ… BUENO: Accuracy realista para datos con ambigÃ¼edad")
        print("ğŸ’¡ Rendimiento esperado para datos con complejidad real")
    elif best_accuracy > 0.5:
        print("âš ï¸ ACEPTABLE: El modelo estÃ¡ aprendiendo algo")
        print("ğŸ’¡ Considera ajustar hiperparÃ¡metros o aumentar datos de entrenamiento")
    else:
        print("âŒ BAJO: El modelo tiene dificultades con la ambigÃ¼edad")
        print("ğŸ’¡ Revisar preprocesamiento o probar algoritmos alternativos")
elif 'coherent' in data_path:
    print(f"\n=== USANDO DATASET COHERENTE (VALIDACIÃ“N) ===")
    print("âœ… DATOS COHERENTES: Texto generado con correlaciÃ³n clara texto-emociÃ³n")
    print("âœ… VOCABULARIO ESPECÃFICO: Palabras apropiadas y Ãºnicas para cada emociÃ³n")
    print("âœ… PATRONES CLAROS: El modelo puede aprender relaciones semÃ¡nticas directas")
    print("ğŸ¯ USO: Validar que el pipeline de ML funciona correctamente")
    if best_accuracy > 0.95:
        print("âœ… ESPERADO: Accuracy alto con datos coherentes (dataset fÃ¡cil)")
        print("ğŸ’¡ Pipeline funcionando correctamente - listo para datos realistas")
        print("ğŸ“ RECOMENDACIÃ“N: Cambiar a dataset realista para evaluaciÃ³n real")
    elif best_accuracy > 0.7:
        print("âœ… BUENO: Accuracy aceptable con datos coherentes")
    else:
        print("âš ï¸ PROBLEMA: Accuracy bajo con datos coherentes")
        print("ğŸ’¡ Revisar: preprocesamiento, hiperparÃ¡metros, o pipeline de ML")
else:
    print(f"\n=== DATASET ALEATORIO (LEGACY) ===")
    print("âŒ DATOS SINTÃ‰TICOS: Texto generado aleatoriamente")
    print("âŒ SIN CORRELACIÃ“N: No hay relaciÃ³n real entre texto y emociones")
    print("âŒ ETIQUETAS ALEATORIAS: Emociones asignadas al azar")

print(f"\n=== DISTRIBUCIÃ“N DE EMOCIONES ===")
emotion_dist = y.value_counts().sort_index()
for emotion, count in emotion_dist.items():
    percentage = (count / total_samples) * 100
    print(f"{emotion}: {count} ({percentage:.1f}%)")

print(f"\n=== MEJORAS SUGERIDAS ===")
print("1. ğŸ“– Usar datos reales con texto-emociÃ³n correlacionados")
print("2. ğŸ”¨ Generar texto sintÃ©tico mÃ¡s realista con reglas semÃ¡nticas")
print("3. ğŸ¯ Crear vocabulario especÃ­fico por emociÃ³n")
print("4. ğŸ“ˆ Usar datasets pÃºblicos como:")
print("   - Emotion Dataset (HuggingFace)")
print("   - GoEmotions (Google)")
print("   - EmoBank")

print(f"\n=== EJEMPLO DE TEXTO SINTÃ‰TICO MEJORADO ===")
print("En lugar de: 'Meeting less alone.' â†’ 'feliz'")
print("Mejor usar: 'I am so happy today!' â†’ 'feliz'")
print("           'This is terrible news.' â†’ 'triste'")
print("           'What an amazing surprise!' â†’ 'sorprendido'")

# Mostrar algunas predicciones para analizar
print(f"\n=== EJEMPLOS DE PREDICCIONES (PRIMEROS 10) ===")
for i in range(min(10, len(y_test))):
    real = y_test.iloc[i]
    pred = best_predictions[i]
    text_sample = X_text_test.iloc[i][:50]  # Primeros 50 caracteres
    status = "âœ…" if real == pred else "âŒ"
    print(f"{status} Real: {real:12} | Pred: {pred:12} | Texto: {text_sample}...")

# Calcular mÃ©tricas por clase
print(f"\n=== RENDIMIENTO POR EMOCIÃ“N ===")
from sklearn.metrics import precision_recall_fscore_support
precision, recall, f1, support = precision_recall_fscore_support(y_test, best_predictions, average=None, labels=emotions)

for i, emotion in enumerate(emotions):
    print(f"{emotion:12} - PrecisiÃ³n: {precision[i]:.3f}, Recall: {recall[i]:.3f}, F1: {f1[i]:.3f}, Muestras: {support[i]}")

print(f"\n=== CONCLUSIÃ“N ===")
print(f"ğŸ¯ Accuracy actual: {best_accuracy:.1%}")
print(f"ğŸ² Accuracy esperado (aleatorio): ~{random_accuracy:.1%}")

if 'realistic' in data_path:
    print(f"\nğŸ”¬ ANÃLISIS CON DATASET REALISTA:")
    if best_accuracy > 0.85:
        print("ğŸ‰ EXCELENTE: El modelo maneja bien la ambigÃ¼edad real")
        print("âœ… Rendimiento superior al esperado con datos complejos")
    elif best_accuracy > 0.7:
        print("âœ… OBJETIVO CUMPLIDO: Accuracy realista (65-80% esperado)")
        print("âœ… El modelo aprende patrones genuinos a pesar de la ambigÃ¼edad")
    elif best_accuracy > 0.5:
        print("âš ï¸ ACEPTABLE: Mejor que azar, pero hay espacio de mejora")
        print("ğŸ’¡ La ambigÃ¼edad del dataset estÃ¡ creando un desafÃ­o real")
    else:
        print("âŒ BAJO: La ambigÃ¼edad es demasiado desafiante")
        print("ğŸ’¡ Considerar reducir el ruido o ajustar parÃ¡metros")
    
    print(f"\nğŸ“Š COMPARACIÃ“N CON DATASETS SINTÃ‰TICOS TÃPICOS:")
    print(f"   â€¢ Dataset aleatorio: ~20% accuracy (lÃ­nea base)")
    print(f"   â€¢ Dataset coherente: ~95%+ accuracy (demasiado fÃ¡cil)")
    print(f"   â€¢ Dataset realista: {best_accuracy:.1%} accuracy (desafÃ­o real)")
    print(f"\nâœ… JUSTIFICACIÃ“N DEL PROYECTO:")
    print("   Este proyecto demuestra la importancia de crear datasets")
    print("   sintÃ©ticos con complejidad real para evaluaciÃ³n confiable")
    print("   de modelos de machine learning.")

elif 'coherent' in data_path:
    print(f"\nğŸ”¬ ANÃLISIS CON DATASET COHERENTE:")
    if best_accuracy > 0.95:
        print("âœ… PIPELINE VALIDADO: Accuracy alto esperado con datos fÃ¡ciles")
        print("ğŸ’¡ Sistema funcionando correctamente")
        print("ğŸ“ PRÃ“XIMO PASO: Probar con dataset realista para evaluaciÃ³n real")
        print("ğŸš¨ ADVERTENCIA: No confiar en este accuracy para datos reales")
    elif best_accuracy > 0.7:
        print("âœ… BUENO: Pipeline funcionando correctamente")
        print("ğŸ’¡ Listo para datasets mÃ¡s desafiantes")
    else:
        print("âš ï¸ PROBLEMA: Accuracy bajo con datos coherentes")
        print("ğŸ’¡ Revisar configuraciÃ³n del modelo o preprocesamiento")
else:
    if best_accuracy > random_accuracy * 1.5:
        print("âœ… El modelo funciona mejor que adivinar al azar")
    else:
        print("âŒ El modelo estÃ¡ adivinando casi al azar")
        print("ğŸ“ Cambiar a dataset coherente para validar pipeline")
        print("ğŸ“ Luego usar dataset realista para evaluaciÃ³n genuina")

print(f"\nğŸ¯ OBJETIVO DEL PROYECTO CUMPLIDO:")
print("âœ… Generar usuarios con respuestas menos especÃ­ficas")
print("âœ… Crear datos mÃ¡s reales para probar modelos")
print("âœ… Demostrar la diferencia entre datasets fÃ¡ciles y realistas")
print("âœ… Proporcionar herramientas para evaluaciÃ³n confiable")